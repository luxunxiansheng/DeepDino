[GLOBAL]

game_log_file_path= ./log

log_interval= 100

;final value of epsilon
final_epsilon = 0.0001  

;starting value of epsilon
init_epsilon = 0.1  

working_agent = DQNAgent

; train or replay
working_mode = train

; if train, if resume or not
resume= False


[GAME]
game_url      = http://apps.thecodepost.org/trex/trex.html
chrome_driver_path = chromedriver

reward_if_well_done=0.1
reward_if_crash=-1

; a float number to control how fast the dino runs. Defualt is 0.
acceleration = 0


; It is interesting to set the carton dino visible or invisible, 
; which can help to know better what makes the deep neural network 
; understand the patten of the game
dino_invisible= False



[DQN]
momentum = 0

;decay rate of past observations original 0.99
gamma = 0.99  

;timesteps to observe before training
observations = 150



;number of previous transitions to remember
replay_memory_capacity = 100000 

explore = 100000

;size of minibatch
batch = 32  
frame_per_action = 1
learning_rate = 0.0001

update_target_interval=10000

; DQN: True, Double-DQN: False
dqn= True    

model_name = DeepMindNetwork






